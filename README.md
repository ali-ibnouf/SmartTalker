<div dir="ltr">

# ğŸ—£ï¸ SmartTalker

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.115-009688.svg)](https://fastapi.tiangolo.com/)
[![Tests](https://img.shields.io/badge/tests-171%20passed-brightgreen.svg)]()

**Digital Human AI Agent Platform â€” Arabic-First, Open-Source AI Stack**

SmartTalker is an end-to-end platform for building real-time digital human AI agents. It takes speech or text input and produces a talking avatar video response â€” powered entirely by open-source AI models. The platform is designed with Arabic as the primary language, targeting MENA markets, but supports multilingual use cases out of the box.

### Key Features

- **Full Speech Pipeline** â€” ASR, LLM reasoning, TTS, and talking-head video generation in a single API call
- **Arabic-First** â€” Native Arabic support across all pipeline layers (ASR, LLM, TTS)
- **Real-Time Communication** â€” REST API, WebSocket, and WebRTC interfaces for flexible integration
- **WhatsApp Integration** â€” Built-in WhatsApp Business API client for conversational AI over messaging
- **Voice Cloning** â€” Clone voices from 3â€“10 second reference audio samples
- **Emotion-Aware** â€” Detects and applies emotion to both speech synthesis and avatar animation
- **Production-Ready** â€” Redis rate limiting, API key auth, Prometheus metrics, Docker deployment, and structured JSON logging
- **Cost-Efficient** â€” Runs on a single GPU server at $50â€“150/month using fully open-source models

> **First Client:** BusTickets Pro â€” WhatsApp bus booking assistant
> **Cost Target:** $50â€“150/month operational

---

## ğŸ—ï¸ Architecture

SmartTalker uses a 6-layer pipeline architecture:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        SmartTalker Pipeline                     â”‚
â”‚                                                                 â”‚
â”‚  ğŸ¤ Audio In                                          ğŸ¬ Video Out â”‚
â”‚      â”‚                                                    â–²     â”‚
â”‚      â–¼                                                    â”‚     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  ASR   â”‚â”€â”€â–¶â”‚  LLM   â”‚â”€â”€â–¶â”‚  TTS   â”‚â”€â”€â–¶â”‚ Video  â”‚â”€â”€â–¶â”‚Upscale â”‚ â”‚
â”‚  â”‚Fun-ASR â”‚   â”‚Qwen 2.5â”‚   â”‚CosyVoiceâ”‚  â”‚EchoMimicâ”‚  â”‚RealESR â”‚ â”‚
â”‚  â”‚  Nano  â”‚   â”‚  14B   â”‚   â”‚  3.0   â”‚   â”‚  V2    â”‚  â”‚  GAN   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚          Orchestrator: FastAPI + WebSocket + Redis        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Layer | Tool | Purpose |
|-------|------|---------|
| 1. ASR | [Fun-ASR Nano](https://github.com/modelscope/FunASR) | Speech â†’ Text |
| 2. LLM | [Qwen 2.5 14B](https://ollama.com/library/qwen2.5) via Ollama | Reasoning & Response |
| 3. TTS | [CosyVoice 3.0](https://github.com/FunAudioLLM/CosyVoice) | Text â†’ Speech |
| 4. Video | [EchoMimicV2](https://github.com/antgroup/echomimic_v2) | Audio â†’ Talking Head |
| 5. Upscale | [RealESRGAN](https://github.com/xinntao/Real-ESRGAN) + CodeFormer | Quality Enhancement |
| 6. Orchestrator | FastAPI + WebSocket + Redis | Coordination |

---

## ğŸš€ Quick Start

### Prerequisites

- **OS:** Ubuntu 22.04 LTS
- **GPU:** NVIDIA RTX 4090 (24GB VRAM) or equivalent
- **NVIDIA Driver:** 545+
- **Docker:** 24.0+
- **Python:** 3.10+

### Option 1: One-Click Setup (Recommended)

```bash
git clone https://github.com/ali-ibnouf/SmartTalker.git
cd SmartTalker
chmod +x setup.sh
sudo ./setup.sh
```

### Option 2: Docker Compose

```bash
# Clone the repo
git clone https://github.com/ali-ibnouf/SmartTalker.git
cd SmartTalker

# Configure environment
cp .env.example .env
# Edit .env with your settings

# Build and run
docker compose up -d

# Pull the LLM model
docker exec smarttalker-ollama ollama pull qwen2.5:14b

# Download AI models
bash scripts/download_models.sh
```

### Option 3: Local Development

```bash
# Create virtual environment
python3.10 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Configure
cp .env.example .env

# Download models
bash scripts/download_models.sh

# Start Ollama (separate terminal)
ollama serve

# Run the app
make dev
```

### Verify Installation

```bash
# Health check
curl http://localhost:8000/api/v1/health

# Test text-to-speech
curl -X POST http://localhost:8000/api/v1/text-to-speech \
  -H "Content-Type: application/json" \
  -d '{"text": "Ù…Ø±Ø­Ø¨Ø§Ù‹ Ø¨ÙƒÙ… ÙÙŠ Ø³Ù…Ø§Ø±Øª ØªÙˆÙƒØ±", "language": "ar"}'
```

---

## ğŸ“ Project Structure

```
SmartTalker/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py           # Pydantic Settings
â”‚   â”œâ”€â”€ main.py             # FastAPI application
â”‚   â”œâ”€â”€ pipeline/           # AI processing engines
â”‚   â”‚   â”œâ”€â”€ orchestrator.py # Pipeline coordinator
â”‚   â”‚   â”œâ”€â”€ asr.py          # Fun-ASR Nano
â”‚   â”‚   â”œâ”€â”€ llm.py          # Qwen 2.5 via Ollama
â”‚   â”‚   â”œâ”€â”€ tts.py          # CosyVoice 3.0
â”‚   â”‚   â”œâ”€â”€ video.py        # EchoMimicV2
â”‚   â”‚   â”œâ”€â”€ upscale.py      # RealESRGAN + CodeFormer
â”‚   â”‚   â””â”€â”€ emotions.py     # Emotion detection
â”‚   â”œâ”€â”€ api/                # REST + WebSocket API
â”‚   â”œâ”€â”€ integrations/       # WhatsApp, WebRTC, Storage
â”‚   â””â”€â”€ utils/              # Audio, video, logging
â”œâ”€â”€ tests/                  # Test suite
â”œâ”€â”€ scripts/                # Setup & maintenance scripts
â”œâ”€â”€ avatars/                # Avatar reference images
â”œâ”€â”€ voices/                 # Voice reference audio
â”œâ”€â”€ docs/                   # Documentation
â”œâ”€â”€ docker-compose.yml      # 3-service stack
â”œâ”€â”€ Dockerfile              # Multi-stage build
â”œâ”€â”€ Makefile                # Build targets
â””â”€â”€ requirements.txt        # Pinned dependencies
```

---

## ğŸ”§ Make Targets

```bash
make setup          # Initial setup (Linux)
make setup-win      # Initial setup (Windows)
make build          # Build Docker images
make run            # Start all services
make dev            # Run locally with hot reload
make test           # Run test suite
make lint           # Run linters
make format         # Format code
make download-models # Download AI models
make clean          # Clean generated files
make help           # Show all targets
```

---

## ğŸ“– API Endpoints

| Method | Endpoint | Description |
|--------|----------|-------------|
| POST | `/api/v1/text-to-speech` | Text â†’ Audio |
| POST | `/api/v1/audio-chat` | Audio â†’ Audio |
| POST | `/api/v1/text-to-video` | Text â†’ Video |
| POST | `/api/v1/voice-clone` | Clone a voice |
| GET | `/api/v1/voices` | List voices |
| GET | `/api/v1/health` | System health |
| WS | `/ws/chat/{avatar_id}` | Real-time chat |

Full API docs: http://localhost:8000/docs

---

## ğŸ“„ License

MIT License â€” see [LICENSE](LICENSE) for details.

---

</div>

<div dir="rtl">

## ğŸŒ Ø³Ù…Ø§Ø±Øª ØªÙˆÙƒØ± â€” Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©

### Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©

**Ø³Ù…Ø§Ø±Øª ØªÙˆÙƒØ±** Ù‡Ùˆ Ù…Ù†ØµØ© ÙˆÙƒÙŠÙ„ Ø°ÙƒØ§Ø¡ Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø±Ù‚Ù…ÙŠ Ø¨Ø´Ø±ÙŠØŒ Ù…ØµÙ…Ù… Ø®ØµÙŠØµØ§Ù‹ Ù„Ù„Ø£Ø³ÙˆØ§Ù‚ Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙÙŠ Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø´Ø±Ù‚ Ø§Ù„Ø£ÙˆØ³Ø· ÙˆØ´Ù…Ø§Ù„ Ø£ÙØ±ÙŠÙ‚ÙŠØ§ (MENA).

### Ø§Ù„Ù…Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©

- ğŸ¤ **Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…** â€” Ø¯Ø¹Ù… ÙƒØ§Ù…Ù„ Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Fun-ASR
- ğŸ§  **Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ** â€” Ù…Ø­Ø§Ø¯Ø«Ø© Ø·Ø¨ÙŠØ¹ÙŠØ© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ù…Ø¹ Qwen 2.5
- ğŸ—£ï¸ **ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù…** â€” ØµÙˆØª Ø¹Ø±Ø¨ÙŠ Ø·Ø¨ÙŠØ¹ÙŠ Ù…Ø¹ CosyVoice
- ğŸ¬ **ÙÙŠØ¯ÙŠÙˆ Ø°ÙƒÙŠ** â€” Ø£ÙØ§ØªØ§Ø± Ù…ØªØ­Ø±Ùƒ ÙˆØ§Ù‚Ø¹ÙŠ Ù…Ø¹ EchoMimicV2
- ğŸ“± **ÙˆØ§ØªØ³Ø§Ø¨** â€” ØªÙƒØ§Ù…Ù„ Ù…Ø¨Ø§Ø´Ø± Ù…Ø¹ ÙˆØ§ØªØ³Ø§Ø¨ Ù„Ù„Ø£Ø¹Ù…Ø§Ù„

### Ø§Ù„Ø¹Ù…ÙŠÙ„ Ø§Ù„Ø£ÙˆÙ„: BusTickets Pro

Ù†Ø¸Ø§Ù… Ø­Ø¬Ø² ØªØ°Ø§ÙƒØ± Ø§Ù„Ø­Ø§ÙÙ„Ø§Øª Ø¹Ø¨Ø± ÙˆØ§ØªØ³Ø§Ø¨ â€” ÙŠØªØ­Ø¯Ø« Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø·Ù„Ø§Ù‚Ø© ÙˆÙŠÙˆÙØ± ØªØ¬Ø±Ø¨Ø© Ø­Ø¬Ø² Ø³Ù‡Ù„Ø© ÙˆØ³Ø±ÙŠØ¹Ø©.

### Ø§Ù„Ø¨Ø¯Ø¡ Ø§Ù„Ø³Ø±ÙŠØ¹

```bash
# Ø§Ø³ØªÙ†Ø³Ø§Ø® Ø§Ù„Ù…Ø´Ø±ÙˆØ¹
git clone https://github.com/ali-ibnouf/SmartTalker.git
cd SmartTalker

# Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
chmod +x setup.sh
sudo ./setup.sh

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø¯Ù…Ø§Øª
docker compose up -d
```

### Ø§Ù„ØªÙƒÙ„ÙØ© Ø§Ù„ØªØ´ØºÙŠÙ„ÙŠØ©

Ø§Ù„Ù‡Ø¯Ù: **50â€“150 Ø¯ÙˆÙ„Ø§Ø± Ø´Ù‡Ø±ÙŠØ§Ù‹** â€” Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø£Ø¯ÙˆØ§Øª Ù…ÙØªÙˆØ­Ø© Ø§Ù„Ù…ØµØ¯Ø± Ø¨Ø§Ù„ÙƒØ§Ù…Ù„.

</div>
